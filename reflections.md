Reflections
===========

<!--
This file generated by the build script at ./Build.hs from the files in
./reflections.  If you want to edit this, edit those instead!
-->

*[2016][]* / *[2017][]* / *[2018][]* / *2019*

[2016]: https://github.com/mstksg/advent-of-code-2016/blob/master/reflections.md
[2017]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md
[2018]: https://github.com/mstksg/advent-of-code-2018/blob/master/reflections.md

[Available as an RSS Feed][rss]

[rss]: http://feeds.feedburner.com/jle-advent-of-code-2019

Table of Contents
-----------------

* [Day 1](#day-1)
* [Day 2](#day-2)
* [Day 3](#day-3)
* [Day 4](#day-4)
* [Day 6](#day-6)
* [Day 8](#day-8)
* [Day 10](#day-10)
* [Day 11](#day-11)
* [Day 17](#day-17)

Day 1
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day01.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d01p]* / *[Code][d01g]* / *[Rendered][d01h]*

[d01p]: https://adventofcode.com/2019/day/1
[d01g]: https://github.com/mstksg/advent-of-code-2019/blob/master/src/AOC/Challenge/Day01.hs
[d01h]: https://mstksg.github.io/advent-of-code-2019/src/AOC.Challenge.Day01.html


Haskell has a history of making Day 1's seem trivial :)  In this case it's a
straightforward map:

```haskell
fuel :: Int -> Int
fuel = subtract 2 . (`div` 3)

part1 :: [Int] -> Int
part1 = sum . map fuel

part2 :: [Int] -> Int
part2 = sum . map (sum . drop 1 . takeWhile (>= 0) . iterate fuel)
```

These can be parsed with `map read . lines`!

I accidentally forgot the `drop 1` the first time I submitted, so I hit the
cooldown.  Teaches me to remember to test all my answers next time :)


### Day 1 Benchmarks

```
>> Day 01a
benchmarking...
time                 1.236 μs   (1.235 μs .. 1.237 μs)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 1.235 μs   (1.235 μs .. 1.236 μs)
std dev              1.308 ns   (986.5 ps .. 1.753 ns)

* parsing and formatting times excluded

>> Day 01b
benchmarking...
time                 20.26 μs   (20.19 μs .. 20.39 μs)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 20.22 μs   (20.19 μs .. 20.29 μs)
std dev              141.3 ns   (69.24 ns .. 253.6 ns)

* parsing and formatting times excluded
```



Day 2
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day02.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d02p]* / *[Code][d02g]* / *[Rendered][d02h]*

[d02p]: https://adventofcode.com/2019/day/2
[d02g]: https://github.com/mstksg/advent-of-code-2019/blob/master/src/AOC/Challenge/Day02.hs
[d02h]: https://mstksg.github.io/advent-of-code-2019/src/AOC.Challenge.Day02.html

So the bytecode/VM problems start day 2 this year, eh?

This one was also pretty straightforward.  For these types of problems, I like
to use `Data.IntMap` or `Data.Sequence` for the memory, since they both have
*O(log n)* indexing.  `Data.Sequence` is the better choice here because it's
basically `IntMap` with the indices (0, 1, 2 ...) automatically given for us :)

I usually use `Data.Sequence` instead of `Data.Vector` because it has a better
story when you want to change the length (by adding or removing elements):
`Data.Vector` is very bad, unless you have some sort of amortized abstraction.
However, in this case we don't ever change the length, so `Data.Vector` is
technically just as good here :)

So parsing:

```haskell
import           Data.List.Split (splitOn)
import           Data.Sequence (Seq(..))
import qualified Data.Sequence as Seq

type Memory = (Int, Seq Int)

parse :: String -> Memory
parse = (0,) . Seq.fromList . map read . splitOn ","
```

We write our stepping function:

```haskell
step :: Memory -> Maybe Memory
step (p, r) = do
    o <- Seq.lookup p r >>= \case
      1 -> pure (+)
      2 -> pure (*)
      _ -> empty
    [a, b, c] <- traverse (`Seq.lookup` r) [p+1 .. p+3]
    [y, z]    <- traverse (`Seq.lookup` r) [a,b]
    pure (p + 4, Seq.update c (o y z) r)
```

And away we go!

```haskell
runProg :: Memory -> Maybe Int
runProg m@(_,r) = case step m of
  Nothing -> Seq.lookup 0 r
  Just m' -> runProg m'

part1 :: String -> Maybe Int
part1 str = runProg (p, r')
  where
    (p,r) = parse str
    r'    = Seq.update 1 12 . Seq.update 2 2 $ r
```

For part 2 we can just do a brute force search

```haskell
part2 :: String -> Maybe (Int, Int)
part2 str = listToMaybe
    [ (noun, verb)
    | noun <- [0..99]
    , verb <- [0..99]
    , let r' = Seq.update 1 noun . Seq.update 2 verb $ r
    , runProg (p, r') == Just 19690720
    ]
  where
    (p, r) = parse str
```

This doesn't take too long on my machine!  But for my [actual solution][d02g],
I actually used a binary search (that I had coded up for last year). I
noticed that `noun` increases the answer by a lot, and `verb` increases it by a
little, so by doing an binary search on `noun`, then an binary search
on `verb`, you can get a good answer pretty quickly.  My part 2 time (470 μs)
is only twice as long as my part 1 time (260 μs) with the binary search. Happy
that some prep time paid off :)

```haskell
part2' :: String -> Maybe (Int, Int)
part2' str =  do
    noun <- binaryMinSearch (\i ->
        runProg (p, Seq.update 1 (i + 1) r) > Just moon
      ) 0 99
    let r' = Seq.update 1 noun r
    verb <- binaryMinSearch (\i ->
        runProg (p, Seq.update 2 (i + 1) r) > Just moon
      ) 0 99
    pure (noun, verb)
  where
    moon = 19690720
    (p, r) = parse str
```

This gets us an O(log n) search instead of an O(n^2) search, cutting down times
pretty nicely.

Just for the same of completion, I'm including my implementation of
`binaryMinSearch` here.  It's tucked away in my utilities/common
functionality file normally!

```haskell
-- | Find the lowest value where the predicate is satisfied within the
-- given bounds.
binaryMinSearch
    :: (Int -> Bool)
    -> Int                  -- ^ min
    -> Int                  -- ^ max
    -> Maybe Int
binaryMinSearch p = go
  where
    go !x !y
        | x == mid || y == mid = Just (x + 1)
        | p mid                = go x mid
        | otherwise            = go mid y
      where
        mid = ((y - x) `div` 2) + x
```


### Day 2 Benchmarks

```
>> Day 02a
benchmarking...
time                 153.2 μs   (152.8 μs .. 153.7 μs)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 153.1 μs   (152.8 μs .. 153.8 μs)
std dev              1.586 μs   (787.1 ns .. 2.543 μs)

* parsing and formatting times excluded

>> Day 02b
benchmarking...
time                 2.131 ms   (2.127 ms .. 2.136 ms)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 2.140 ms   (2.137 ms .. 2.144 ms)
std dev              10.41 μs   (8.780 μs .. 13.03 μs)

* parsing and formatting times excluded
```



Day 3
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day03.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d03p]* / *[Code][d03g]* / *[Rendered][d03h]*

[d03p]: https://adventofcode.com/2019/day/3
[d03g]: https://github.com/mstksg/advent-of-code-2019/blob/master/src/AOC/Challenge/Day03.hs
[d03h]: https://mstksg.github.io/advent-of-code-2019/src/AOC.Challenge.Day03.html

As another data processing one, I feel like this might be another win for
Haskell as well :)  My part 2 leaderboard position was much higher than my
part1 position --- my suspicion is that the new twist made it difficult for
imperative coders, but the twist was naturally handled in the Haskell case.

First off, I'm going to parse the path not as a series of directions and
numbers, but rather as a list of each individual step to take.  This was
similar to my approach for [2016 Day 1][y16d1].  I'm using my favorite type for
describing points, [V2][], because it has a really useful `Num` instance to
support addition of points.

[y16d1]: https://adventofcode.com/2016/day/1
[V2]: https://hackage.haskell.org/package/linear/docs/Linear-V2.html

```haskell
import           Data.List.Split
import           Linear.V2

parsePath :: String -> [V2 Int]
parsePath = concatMap parsePoint . splitOn ","
  where
    parsePoint (d:ns) = replicate (read ns) $ case d of
      'U' -> V2   0    1
      'R' -> V2   1    0
      'D' -> V2   0  (-1)
      'L' -> V2 (-1)   0
    parsePoint _      = []
```

Now, our list of points is simply a cumulative sum, which comes from our best
friend `scanl'` (and family).  We use `scanl1` to get the running sum of all
the direction pieces, and get the set of all points.

```haskell
visited :: [V2 Int] -> Set (V2 Int)
visited = S.fromList . scanl1 (+)
```

Now Part 1 is:

```haskell
part1 :: String -> Int
part1 str = minimum (S.map mannDist (S.intersection xs ys))
  where
    [xs, ys] = map (visited . parsePath) (lines str)
    mannDist (V2 x y) = abs x + abs y
```

Once we get the intersection (the set of points that are
visited by both), we can map the `mannDist` over each intersection and find the
minimum.

Part 2 adds an "extra twist", in that now we also want to keep track of the
time it takes to reach each point.  This requires only a small tweak to
`visited`:

```haskell
visited2 :: [V2 Int] -> Map (V2 Int) Int
visited2 = M.fromListWith min        -- turn it into a map, keeping first seen
         . flip zip [1..]            -- list of (sum, time taken)
         . scanl1 (+)                -- running sum
```

We pair each item in the running sum with the time taken, and so get a map of
points seen to time taken to get to that point.  We make sure to use
`M.fromListWith min` so that we keep the *lowest* time at each point.

Part 2 is very similar, then:

```haskell
part2 :: String -> Int
part2 str = minimum (M.intersectionWith (+) xs ys)
  where
    [xs, ys] = map (visited2 . parsePath) (lines str)
```

Using `M.intersectionWith (+)` instead of `S.intersection`, because we want the
map that has the same keys in both paths, while adding together the times at
each key.

Note that we can actually solve `part1` using `visited2` instead of
`visited`...because we can "forget" the values in a `Map (V2 Int) Int` by using
`M.keysSet :: Map k a -> Set k`.


### Day 3 Benchmarks

```
>> Day 03a
benchmarking...
time                 294.2 ms   (283.0 ms .. 312.4 ms)
                     0.999 R²   (0.995 R² .. 1.000 R²)
mean                 296.4 ms   (292.1 ms .. 301.8 ms)
std dev              6.124 ms   (4.266 ms .. 7.828 ms)
variance introduced by outliers: 16% (moderately inflated)

* parsing and formatting times excluded

>> Day 03b
benchmarking...
time                 290.6 ms   (282.8 ms .. 300.7 ms)
                     0.999 R²   (0.997 R² .. 1.000 R²)
mean                 292.1 ms   (285.6 ms .. 296.9 ms)
std dev              7.021 ms   (3.454 ms .. 10.45 ms)
variance introduced by outliers: 16% (moderately inflated)

* parsing and formatting times excluded
```



Day 4
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day04.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d04p]* / *[Code][d04g]* / *[Rendered][d04h]*

[d04p]: https://adventofcode.com/2019/day/4
[d04g]: https://github.com/mstksg/advent-of-code-2019/blob/master/src/AOC/Challenge/Day04.hs
[d04h]: https://mstksg.github.io/advent-of-code-2019/src/AOC.Challenge.Day04.html

I should probably appreciate these Haskell freebies while they still last :)  I
have a feeling they're not going to be this frictionless for long!

It's handy to have a function for giving us consecutive pairs of items:

```haskell
consecs :: [a] -> [(a,a)]
consecs xs = zip xs (tail xs)
```

Now for the fun part: making our filters!  For part 1, we have two filters on
the digits: first, that the digits are monotonic, and second, that at least one
pair of consecutive digits matches:

```haskell
mono :: Ord a => [a] -> Bool
mono = all (\(x,y) -> y >= x) . consecs

dups :: Eq a => [a] -> Bool
dups = any (\(x,y) -> x == y) . consecs
```

For part 2, we have two filters: the same `mono` filter, but also that we have
a group that is *exactly* length two.  For that we can use `group`, which
groups a list into chunks of equal items: `group "abbbcc" == ["a","bbb","cc"]`.
We then check if any of the chunks have a length of exactly two:

```haskell
strictDups :: Eq a => [a] -> Bool
strictDups = any ((== 2) . length) . group
```

And from here, we just run our filters on the range and count the number of
items:

```haskell
part1 :: Int -> Int -> Int
part1 mn mx = length . filter (\x -> all ($ show x) [mono, dups      ])
            $ [mn .. mx]

part2 :: Int -> Int -> Int
part2 mn mx = length . filter (\x -> all ($ show x) [mono, strictDups]) . range
            $ [mn .. mx]
```

For parsing the range, we can use `splitOn` again:

```haskell
range :: String -> (x, y)
range str = (x, y)
  where
    [x, y] =  map read (splitOn "-" str)
```

(Also, note to self next time ... if going for time, if you just have two
numbers in your input, just enter the numbers directly into the source file at
first, heh, instead of trying to parse them)



### Day 4 Benchmarks

```
>> Day 04a
benchmarking...
time                 41.12 ms   (40.99 ms .. 41.30 ms)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 41.05 ms   (41.01 ms .. 41.12 ms)
std dev              110.0 μs   (59.89 μs .. 153.2 μs)

* parsing and formatting times excluded

>> Day 04b
benchmarking...
time                 41.27 ms   (41.08 ms .. 41.47 ms)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 41.18 ms   (41.12 ms .. 41.28 ms)
std dev              162.2 μs   (71.70 μs .. 230.8 μs)

* parsing and formatting times excluded
```



Day 6
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day06.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d06p]* / *[Code][d06g]* / *[Rendered][d06h]*

[d06p]: https://adventofcode.com/2019/day/6
[d06g]: https://github.com/mstksg/advent-of-code-2019/blob/master/src/AOC/Challenge/Day06.hs
[d06h]: https://mstksg.github.io/advent-of-code-2019/src/AOC.Challenge.Day06.html

This one is pretty fun in Haskell because you get to use a trick that everyone
loves but nobody gets to use often enough --- [recursive knot tying][knot]!
Basically it's an idiomatic way to do [dynamic programming][dp] in Haskell by
taking advantage of lazy data structures ([this blog post][jelvis] is my
favorite explanation of it).

[knot]: https://wiki.haskell.org/Tying_the_Knot
[dp]: https://en.wikipedia.org/wiki/Dynamic_programming
[jelvis]: http://jelv.is/blog/Lazy-Dynamic-Programming/

The general idea is: let's say we had a map of children to parents, `Map String
String`.  To get the count of all indirect orbits, we can get a `Map String
Int`, a map of children to the number of parents and indirect parents above
them, and get the sum of those.

But how do we compute that?

Here, I'm going to show the "finale" first, and explain the way to get there:

```haskell
type Parent = String
type Child  = String

parents :: Map Child Parent

parentsCount     :: Map Child Int
parentsCount     = parents <&> \p -> case M.lookup p parentsCount of
    Nothing -> 1
    Just n  -> n + 1

parentsOfParents :: Map Child [Parent]
parentsOfParents = parents <&> \p -> case M.lookup p parentsOfParents of
    Nothing -> []
    Just ps -> p:ps
```

Fun, right?  And satisfyingly symmetrical.  That's more or less it!

So, how do we get there?

Let's call the child-parent map and the parent counts map as:

```haskell
type Parent = String
type Child  = String

parents      :: Map Child Parent
parentsCount :: Map Child Int
```


We see that the two have the same keys, so we can "map" a function over the
`parents` map to get `parentsCount`:

```haskell
parentsCount :: Map Child Int
parentsCount = fmap countTheParents parents

countTheParents :: Parent -> Int
countTheParents p = -- ?
```

So how do we `countTheParents`?  Well, we can look the parent up in
`parentsCount`, add one to the answer.  That's because if the parent has `n`
indirect parents, then the child has `n + 1` indirect parents:

```haskell
parentsCount :: Map Child Int
parentsCount = fmap countTheParents parents

countTheParents :: Parent -> Int
countTheParents p = case M.lookup p parentsCount of
    Nothing -> 1        -- count is 1
    Just n  -> n + 1    -- count is 1 + number of parents of parents
```

And that's it!


```haskell
part1 :: Int
part1 = sum parentsCount
````

The interesting thing here is that the leaves of `parentsCount` are lazily
evaluated --- so they can recursively refer to each other!

We can do `part2` in the same way, basically: we can build a list of parents of
parents of parents `"YOU"`, and then a list of parents of parents of parents of
`"SAN"`, and count the number of items that are unique to each.

```haskell
parentsOfParents :: Map Child [Parent]
parentsOfParents = fmap getPP parents

getPP :: Parent -> [Parent]
getPP p = case M.lookup p parentsOfParents of
    Nothing -> []       -- no parents
    Just pp -> p : pp   -- parent consed to parents of parents
```

Note that we actually could have defined `parentsCount` this way too:

```haskell
-- we could have done this
parentsCount :: Map Child Int
parentsCount = fmap length parentsOfParents
```

(But this is worse than the way we did it originally.  Do you see why?)


But anyway, for part 2, we will get the parents of parents of `"YOU"` and the
parents of parents of `"SAN"` and count the items that are unique to each:


```haskell
import qualified Data.Set as S

part2 :: Int
part2 = S.size onlyYou + S.size onlySan
  where
    Just you = M.lookup "YOU" parentsOfParents
    Just san = M.lookup "SAN" parentsOfParents
    onlyYou  = you S.\\ san     -- remove all items in `san` from `you`
    onlySan  = san S.\\ you     -- remove all items in `you` from `san`
```

Note that because the leaves in a `Map` are lazy, this will only actually
construct a list `[Parent]` for the keys that you look up --- parents lists for
keys you don't care about are never assembled.

The nice thing about recursive knot tying is that it gives a very concise and
readable way of saying "what you want":

```haskell
parentsCount :: Map Child Int
parentsCount = fmap countTheParents parents

countTheParents :: Parent -> Int
countTheParents p = case M.lookup p parentsCount of
    Nothing -> 1
    Just n  -> n + 1
```

This code is pretty easy to walk through, and logic of getting the parent count
(`countTheParents`) can be easily read as English: "If you get nothing when
you look up the parent in the parents count, then you only have one parent.
If you *do* get something, then it's one plus that something".

The recursive way here makes it much more readable in a "denotative" sense: you
say what it *is*, and the program/compiler figures out the rest for you.
Because of this, knot tying is often cited as one of the flashy "tech demos" of
denotative programming.  You might have seen someone write `fibs = 1 : 1 :
zipWith (+) fibs (tail fibs)` --- that's the same thing going on here.

And, with a lazy language like Haskell, it means that the leaves remain
unevaluated until we need them.  This will explode in your face in other
languages: if you evaluate all of the leaves "in order", then the first item
will depend on another unevaluated item, which might cause an error in other
languages.

It's always fun when a puzzle demonstrates so well a trick that is essential in
every Haskeller's tool belt :)


### Day 6 Benchmarks

```
>> Day 06a
benchmarking...
time                 425.5 μs   (425.3 μs .. 425.7 μs)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 426.1 μs   (425.5 μs .. 427.9 μs)
std dev              3.627 μs   (511.2 ns .. 8.269 μs)

* parsing and formatting times excluded

>> Day 06b
benchmarking...
time                 410.7 μs   (409.5 μs .. 412.3 μs)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 411.5 μs   (410.5 μs .. 414.1 μs)
std dev              5.402 μs   (1.762 μs .. 9.913 μs)

* parsing and formatting times excluded
```



Day 8
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day08.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d08p]* / *[Code][d08g]* / *[Rendered][d08h]*

[d08p]: https://adventofcode.com/2019/day/8
[d08g]: https://github.com/mstksg/advent-of-code-2019/blob/master/src/AOC/Challenge/Day08.hs
[d08h]: https://mstksg.github.io/advent-of-code-2019/src/AOC.Challenge.Day08.html

This one feels like another Haskell freebie from the early days.  I'm not
complaining, we'll take what we can get :)

We'll define a useful function that counts the number of items in a list that
is equal to a given value:

```haskell
numMatches :: Eq a => a -> [a] -> Int
numMatches x = length . filter (== x)
```

We can use the [`chunksOf`][chunksOf] function from the amazing *[split][]*
package to split our input into chunks of 150.  Then we can find the maximum of
those lines based on their zero count.  Then we encode the answer.

[chunksOf]: https://hackage.haskell.org/package/split/docs/Data-List-Split.html#v:chunksOf
[split]: https://hackage.haskell.org/package/split

```haskell
part1 :: String -> Int
part1 = encodeAnswer
      . minimumBy (comparing (numMatches '0'))
      . chunksOf 150
  where
    encodeAnswer xs = numMatches '1' xs * numMatches '2' xs
```

For part 2, we can use `transpose` turn a list of lines into a list where every
item is all of the pixel data for that pixel.  So it would turn

```
["1234"
,"1234"
,"1234"
]
```

into

```
["111"
,"222"
,"333"
,"333"
]
```

which is exactly what we need to process it.

Finding the 'pixel value' of each pixel is basically the first non-`2` pixel in
each list.  The first way that came to my mind was to use `dropWhile (==
'2')`, but `filter (/= '2')` would have worked as well.

```haskell
part2 :: String -> String
part2 = map (head . dropWhile (== '2'))
      . transpose
      . chunksOf 150
```

And that's it!  Well, almost.  Part 2 requires looking at 0/1 transparency data
and deducing our image.  For me, I wrote a function to display it nicely:

```haskell
showImage :: String -> String
showImage = unlines
          . chunksOf 25         -- number of columns
          . map (\case '0' -> ' '; _ -> '#')
```

```
#  # ###  #  # #### ###
#  # #  # #  # #    #  #
#  # ###  #  # ###  #  #
#  # #  # #  # #    ###
#  # #  # #  # #    #
 ##  ###   ##  #    #
```



### Day 8 Benchmarks

```
>> Day 08a
benchmarking...
time                 290.1 μs   (289.3 μs .. 291.1 μs)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 289.4 μs   (289.1 μs .. 289.9 μs)
std dev              1.156 μs   (526.1 ns .. 1.844 μs)

* parsing and formatting times excluded

>> Day 08b
benchmarking...
time                 269.0 μs   (268.4 μs .. 270.0 μs)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 269.7 μs   (268.8 μs .. 273.6 μs)
std dev              5.521 μs   (1.130 μs .. 12.52 μs)
variance introduced by outliers: 13% (moderately inflated)

* parsing and formatting times excluded
```



Day 10
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day10.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d10p]* / *[Code][d10g]* / *[Rendered][d10h]*

[d10p]: https://adventofcode.com/2019/day/10
[d10g]: https://github.com/mstksg/advent-of-code-2019/blob/master/src/AOC/Challenge/Day10.hs
[d10h]: https://mstksg.github.io/advent-of-code-2019/src/AOC.Challenge.Day10.html

Ah, a 2D lattice map problem -- a staple of Advent of Code, and a favorite to
many (including me!)

The first thing to do is get our map into a format we can use.  Using `V2 Int`
to represent a 2d point (because of its useful instances like `Num` and
`Applicative`), we want to get things into a `Set` of all asteroids.  This is
common enough that I have a pre-made utility function to handle this, but for
demonstration's sake we can implement it like:

```haskell
import qualified Data.Set as S

type Point = V2 Int

asteroidSet :: String -> Set Point
asteroidSet = ifoldMap (\y -> ifoldMap (\x -> crunch (V2 x y)))
            . lines
  where
    crunch p '#' = S.singleton p
    crunch _ _   = S.empty
```

Here I'm using the very handy `ifoldMap :: Monoid m => (Int -> a -> m) -> [a]`
from *[Control.Lens.Indexed][cli]*, which is a very useful function that I hope
will some day make it to *base*.  It's like `foldMap` with also the indices
available.

[cli]: https://www.stackage.org/haddock/lts-14.17/lens-4.17.1/Control-Lens-Indexed.html#v:ifoldMap

Anyway, how do we check if an asteroid is obscured?  There are probably many
good methods, but for me I found all the points in a straight line between two
asteroids, and checked if any of those items are in the asteroid field. (I did
attempt also to get the set of all unique angles, but that method ended up
being 10x slower for some reason? also using floating point equality makes me
feel queasy to my core)

```haskell
lineTo :: Point -> Point -> [Point]
lineTo p0 p1 = [ p0 + t *^ step | t <- [1 .. gcf  - 1] ]
  where
    d@(V2 dx dy) = p1 - p0
    gcf          = gcd dx dy
    step         = (`div` gcf) <$> d
```

Hopefully this shows at least is a good demonstration of why I like `V2 Int` as
`Point` so much.  We take advantages of its instances a lot, including:

*   Using the `Num` instance to compute the deltas, `V2 dx dy = p1 - p0`
*   Using the `Functor` instance to compute the step, `(`div` gcf) <$> d`
*   The handy scalar multiplication function `c *^ v`

I love `V2` :D

Anyway, the main crux of this algorithm is the list comprehension, which
computes the "steps" between the start and finish.

We can now check all the viewable points.

```haskell
viewableIn
    :: Set Point    -- ^ asteroid field
    -> Point        -- ^ vantage point
    -> Set Point    -- ^ all viewable points
viewableIn asteroids p = S.filter good (toList asteroids)
  where
    good q = p /= q
          && all (`S.notMember` asteroids) (lineTo p q)
```

Now we can do part 1:

```haskell
part1 :: Set Point -> Int
part1 asteroids = S.findMax $
    S.map (S.length . viewableIn asteroids) asteroids
```

For part 2, we are going to structure our program as an `unfoldr`.  Unfoldr
generates items while keeping some internal state.  We'll use the "currently
aimed at asteroid" and "asteroids left" as our state, and emit newly eliminated
asteroids.  Then we can simply get the 200th item in the resulting list:

```haskell
part2 :: Set Point -> Point
part2 asteroids =
    unfoldr (shootFrom station) (Nothing, asteroids) !! 199
  where
    station = maximumBy (comparing (S.size . viewableIn asteroids))
                asteroids
```

So we have `shootFrom` as our iterating function. Our "state" will be `Maybe
Point` (the asteroid our blaster is aimed at) and `Set Point`, the asteroid
field remaining.  We'll return `Nothing` when we run out of asteroids to
eliminate.

To implement `shootFrom`, it's useful to be able to sort all viewable asteroids
by the angle they make.  To do that, I made a function `angleFrom` which
computes the angle between two points, clockwise from vertical.  I use `atan2`
with some algebraic finessing to make sure north is the *minimal* amount, and
the direction moves appropriately (we flip its arguments and remember to invert
the `y` axis).

```haskell
angleTo :: Point -> Point -> Double
angleTo p0 p1 = atan2 (-fromIntegral dx) (fromIntegral dy)
  where
    V2 dx dy = p1 - p0
```

We now have all the parts to write `shootFrom`:

```haskell
shootFrom
    :: Point                                    -- ^ station
    -> (Maybe Point, Set Point)                 -- ^ current aim and remaining asteroids
    -> Maybe (Point, Maybe Point, Set Point))   -- ^ blasted asteroid, new aim, leftover field
shootFrom station (aim, asteroids) = guard (not (S.null asteroids)) $>
    case aim of
      Nothing ->
        let targ:next:_ = targetList
        in  (targ, (Just next, S.delete targ asteroids))
      Just a ->
        let targ:next:_ = dropWhile (/= a) targetList
        in  (targ, (Just next, S.delete targ asteroids))
  where
    targetList = cycle
               . sortOn (angleTo station)
               . toList
               $ viewableIn asteroids station
```

Our `targetList` is all of the remaining asteroids that are viewable from our
station, sorted by their angle from the station (0 being north, going
clockwise).  We `cycle :: [a] -> [a]` it, which loops it on itself forever, so
that the "next target" will always be the item *after* the current target.  It
turns `[a,b,c]` into `[a,b,c,a,b,c,a,b,c...]`, so if we want to ask "what
target comes after `c`?", we can see that `a` is after `c` in the cycled
version.

First, we use `guard` to return `Nothing` immediately if there are no asteroids
left.  But if there are asteroids left, we then check what we are aiming at. If
we aren't aiming at anything, just find the first item in the target list and
blast at that.  Otherwise, eat up the target list until we find the item we are
aiming at, and blast at that.  In both cases, the item after our target will be
the new item we are aiming at.

We just then need to make sure we delete our target in the new `Set Point`, to
remove it from the pool.

This one was a nice mix of math, geometry, spatial awareness, and a sense of
iterative algorithms (like `shootFrom`) -- for me, all of the best parts of an
Advent of Code challenge :)


### Day 10 Benchmarks

```
>> Day 10a
benchmarking...
time                 9.808 ms   (9.747 ms .. 9.863 ms)
                     1.000 R²   (0.999 R² .. 1.000 R²)
mean                 9.830 ms   (9.789 ms .. 9.913 ms)
std dev              160.0 μs   (92.01 μs .. 282.7 μs)

* parsing and formatting times excluded

>> Day 10b
benchmarking...
time                 18.01 ms   (17.93 ms .. 18.13 ms)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 18.00 ms   (17.97 ms .. 18.07 ms)
std dev              93.78 μs   (55.36 μs .. 143.3 μs)

* parsing and formatting times excluded
```



Day 11
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day11.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d11p]* / *[Code][d11g]* / *[Rendered][d11h]*

[d11p]: https://adventofcode.com/2019/day/11
[d11g]: https://github.com/mstksg/advent-of-code-2019/blob/master/src/AOC/Challenge/Day11.hs
[d11h]: https://mstksg.github.io/advent-of-code-2019/src/AOC.Challenge.Day11.html

Okay, so I have a bit of backlog on my intcode-related posts (days 5, 7,
and 9).  But we've gotten to the point where the incode implementation isn't
the interesting part, but how we *use* it is, so maybe it's time for a fresh
start :)

This challenge affirmed my choice to use *[conduit][]* to model my Intcode VM.
(I actually use *[conduino][]*, my own lightweight alternative to *conduit*,
because it was able to handle something in Day 7 that I couldn't easily get
*conduit* to handle.  But since *conduit* is an actual industry-ready library
that is commonly used, I'm going to write this tutorial in terms of it instead)

[conduit]: https://hackage.haskell.org/package/conduit
[conduino]: https://hackage.haskell.org/package/conduino

For a "preview" of the end, my final code is more or less:

```haskell
fullBot :: Memory -> Conduit i o (State Hull) ()
fullBot m = sensor
         .| intcodeVM m
         .| painterMover
```

For those unfamiliar with *conduit*, `ConduitT i o` is a monad transformer
(like `StateT s`, or `ReaderT r`, or `WriterT w`, etc.) that offers two new
primitives:

```haskell
await :: ConduitT i o m (Maybe i)
yield :: o -> ConduitT i o m ()
```

This *should* feel very similar to similar actions from `StateT`, `ReaderT`,
and `WriterT`:

```haskell
-- similar in form to 'await'
get :: StateT  s m s
ask :: ReaderT r m r

-- similar in form to 'yield'
put  :: s -> StateT  s m ()
tell :: w -> WriterT w m ()
```

You can think of `await` like reading from an input pipe, like *stdin*: you pick off the next
item the pipe is delivering you.  You can think of `yield` like writing to an
output pipe, like *stdout*.  You can then combine conduits to create new
conduits, like `c1 .| c2` -- it feeds the output of `c1` into the input of
`c2`, etc.

So for a type like `ConduitT i o m a`, `i` is the input stream's type, `o` is
the output stream's type, `m` is the underlying monad, and `a` is the result
type that is yielded when computation finishes.


My VM machine is essentially:

```haskell
intcodeVM :: Memory -> ConduitT Int Int m Memory
```

Given some starting memory state, you return a `ConduitT Int Int m Memory`:
take `Int`s as input, output `Int`s, and when it's done, output the finished
`Memory` once we halt.

So we have our transforming pipe...what sort of input does it need, and how are
we handling the output?

The input stream is relatively simple.  Let's put together a hull state:

```haskell
type Point = V2 Int         -- V2, from linear library
data Color = Black | White

data Hull = Hull
    { hDir :: Point         -- ^ unit-length direction vector
    , hPos :: Point
    , hMap :: Map Point Color
    }

emptyHull :: Hull
emptyHull = Hull (V2 0 1) 0 M.empty
```

The underlying monad of our `Conduit` (that all components will be able to
access) will be `State Hull`.

Our input pipe is will read the current hull point and output `0` or `1` based
on black or white:

```haskell
sensor :: ConduitT i Int (State Hull) a
sensor = forever $ do
    Hull _ p m <- get
    case M.lookup p m of
      Nothing    -> yield 0     -- black
      Just Black -> yield 0     -- black
      Just White -> yield 1     -- white
```

It'll just keep on reading and yielding, forever and ever.

Our output pipe will read the input of `intcodeVM` and adjust the state
appropriately --- it's slightly trickier because we have to parse the input and
modify the state.  `await` returns a `Maybe`, so if we get two `Just`'s then we
make our changes and repeat it all over again.  Otherwise, we're done.

```haskell
painterMover :: ConduitT Int o (State Hull) ()
painterMover = do
    color <- fmap parseColor <$> await
    turn  <- fmap parseTurn  <$> await
    case (color, turn) of
      (Just c, Just t) -> do
        modify $ \(Hull d p m) ->
          let d' = t d
          in  Hull d' (p + d') (M.insert p c m)
        painterMover                -- recurse
      _                ->
        pure ()                     -- we're done!
  where
    parseColor 0 = Black
    parseColor 1 = White
    parseTurn  0 (V2 x y) = V2 (-y)   x     -- turn left
    parseTurn  1 (V2 x y) = V2   y  (-x)    -- turn right
```

And that's it!

```haskell
fullBot :: Memory -> Conduit i o (State Hull) ()
fullBot m = sensor
         .| intcodeVM m
         .| painterMover
```

We can run a full pipeline using `runConduit`:

```haskell
part1 :: Memory -> Int
part1 m = M.size m
  where
    Hull _ p m = execState (runConduit (fullBot m)) emptyHull
```

Part 2 is the same thing but we start on a painted hull:


```haskell
whiteHull :: Hull
whiteHull = Hull (V2 0 1) 0 (M.singleton 0 White)

part1 :: Memory -> Map Point Color
part1 m = m
  where
    Hull _ _ m = execState (runConduit (fullBot m)) whiteHull
```

The nice thing I like about the conduit method is that it lends itself really
well to "hooking up" the machine with input streams and output processing!  For
a machine that basically simulates stdin and stdout, it works very well, I
think!  You only need to think:

1.  How am I generating input?
2.  How am I processing output?

And your entire program will just be `generator .| intcodeVM m .| processor`.
This also worked pretty well as a mental model for Day 7 as well, because we
can easily pipe multiple independent machines: `intcodeVM m .| intcodeVM m .|
intcodeVM m`, and they will all maintain separate and independent memories as
they feed items to each other.  *conduit* handles all of the actual message
passing, and all you have to do is assemble your pipeline and let it churn
away!

Note that even if you didn't structure your intcode VM as a Conduit, it's
pretty easy to "turn it into" a `ConduitT Int Int`.  Integrating it into
conduit is nice even if you didn't intend to do it originally, using basic do
notation and combinations of `await` and `yield` and recursion.

#### Writing your `intcodeVM` conduit

Is this you?  Do you have your intcode VM written in a way that doesn't really
support streaming input easily, but want to convert it into a conduit?  Are you
worried you will have to throw everything away and start from scratch?

Fear not --- there is a way to wrap an existing intcode VM implementation in
`Conduit` so you can get that sweet `intcodeVM m :: Conduit Int Int m Memory`
action!

All you need to do is, using your existing implementation, write this function:

```haskell
type Memory         -- contains current position, register state, and base

runMemory
    :: Memory                   -- ^ initial memory
    -> ( [Int]                  -- ^ output emitted before halt or input asked
       , Either
           Memory               -- ^ either a halted machine ...
           (Int -> Memory)      -- ^ ... or a continuation awaiting one input
       )
```

From there, you can construct `intcodeVM` like this:

```haskell
intcodeVM :: Memory -> ConduitT Int Int m Memory
intcodeVM m0 = do
    mapM_ yield outs
    case next of
      Left  finalMemory -> pure finalMemory     -- halt!
      Right nextWith    -> do
        inp <- await
        case inp of
          Nothing -> pure ()                    -- no more input so what can you do, right?
          Just i  -> intcodeVM (nextWith i)     -- recurse!
  where
    (outs, next) = runMemory m0
```

And there you have it!  You can now do the rest of the code described in this
post :)


### Day 11 Benchmarks

```
>> Day 11a
benchmarking...
time                 680.6 ms   (674.0 ms .. 685.7 ms)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 678.8 ms   (677.3 ms .. 679.8 ms)
std dev              1.519 ms   (752.3 μs .. 1.963 ms)
variance introduced by outliers: 19% (moderately inflated)

* parsing and formatting times excluded

>> Day 11b
benchmarking...
time                 47.59 ms   (47.41 ms .. 47.72 ms)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 47.69 ms   (47.61 ms .. 47.90 ms)
std dev              251.3 μs   (51.33 μs .. 443.0 μs)

* parsing and formatting times excluded
```



Day 17
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day17.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d17p]* / *[Code][d17g]* / *[Rendered][d17h]*

[d17p]: https://adventofcode.com/2019/day/17
[d17g]: https://github.com/mstksg/advent-of-code-2019/blob/master/src/AOC/Challenge/Day17.hs
[d17h]: https://mstksg.github.io/advent-of-code-2019/src/AOC.Challenge.Day17.html

It's been a while since one of these!  I spent a lot of last week traveling and
it's been tough getting through the backlog :)

For today I'm only going to be discussing some parts of the solution that I
think are particularly interesting in Haskell: in particular, Part 2's path
construction and compression.

Once you have a set of points, it's useful to try to figure out the path to the
end.  From the constraints of the problem, we can make an educated guess that
our "pathfinding" has to be extremely simple in order to accommodate for the
small program size we can give.  Basically, it will be:

1.  Is there a spot in front of us?  If so, step forward and repeat from step 1.
2.  Otherwise, is there a spot to our left?  If so, turn left and repeat from
    step 1.
3.  Otherwise, is there a spot to our right?  If so, turn right and repeat from
    step 1.
4.  Otherwise, we've reached the end.

I'm going to use `Set Point` (where `Point` is `V2 Int`, for reasons discussed in
earlier problems) to describe our scaffolding, and a data type to keep track of
bot state.  The directionality will be tracked by keeping a unit vector in the
direction the bot is facing.

```haskell
type Point = V2 Int
data BotState = BS { bsPos :: Point, bsDir :: Point }
data Move = TurnLeft | GoForward | TurnRight
  deriving Eq

findPath :: Set Point -> BotState -> [Move]
findPath scaff = unfoldr go
  where
    go (BS p0 d0@(V2 dx dy))
        | forward   `S.member` scaff = Just (GoForward, BS forward d0       )
        | leftward  `S.member` scaff = Just (TurnLeft , BS p0      turnLeft )
        | rightward `S.member` scaff = Just (TurnRight, BS p0      turnRight)
      where
        forward   = p0 + d0
        turnLeft  = V2 dy    (-dx)
        turnRight = V2 (-dy) dx
        leftward  = p0 + turnLeft
        rightward = p0 + turnRight
```

To turn our path into a "run-length encoding" of instructions, we will convert
them into `Either Int Int`, where `Left n` means "turn left and go `n`
forward", and `Right n` means "turn right and go `n` forwards".  The easiest
way to do that is probably to use `group` and `chunksOf`

```haskell
pathToProg :: [Move] -> [Either Int Int]
pathToProg = traverse toInstr . chunksOf 2 . group
  where
    toInstr [[TurnLeft ],fs] = Just $ Left  (length fs)
    toInstr [[TurnRight],fs] = Just $ Right (length fs)
    toInstr _                = Nothing
```

Alright, so now form a `Set Point` and a `BotState` starting point, we get the
run-length encoding of our journey.  However, we now need to turn that into
repetitions of three distinct chunks, `A`, `B`, and `C`.

To do this, we can write a general combinator to turn *any* `[a]` into
encodings in terms of `A`, `B`, and `C` subprograms.  Let's call it:

```haskell
findProgs :: Eq a => [a] -> Maybe ([a], [a], [a])
```

If we start thinking about how we can pick these things, we notice some
interesting properties.  For example, for a string like `abcdefg`, we have many
possible options for `A`: it's either `a` or `ab` or `abc` or `abcd`, etc.  `A`
must be a prefix of our string. However, once we "commit" to an `A`, then that
also gives us our possibilities for `b`: in the same way, `b` must be a prefix
of the remaining string after we "eliminate" `A`.  So if we "pick" `A` to be
`abc`, the `B` can be either `d` or `de` or `def` or `defg`, etc.

This sort of "if we pick this ... then we can pick that ... and if we pick that
..." system is exactly what *Logic Programming* is great for!  And we can
actually do some nice logic programing in Haskell using the List monad.  I've
actually written about using the list monad for this purpose [multiple][wgc]
[times][money] over the years.

[wgc]: https://blog.jle.im/entries/series/+monadplus-success-failure-monads.html
[money]: https://blog.jle.im/entry/unique-sample-drawing-searches-with-list-and-statet.html

So let's lay out our full algorithm:

1.  We can pick `A` from any prefix of our string.
2.  Once we break out occurrences of our chosen `A` from the string, we can now
    pick `B` from any unbroken prefix of the remaining string.
3.  Once we break out occurrences of our chosen `B` from the string, we can now
    pick `C` from any unbroken prefix of the remaining string.
4.  Once we break out occurrences of our chosen `C` from the string, we only
    have a "real" solution if there are no other unclaimed items in the string.

This all translates pretty directly to usage of the `List` monad.  `findProgs`
will now return all valid `A`/`B`/`C` pairs:

```haskell
findProgs :: Eq a => [a] -> [([a], [a], [a])]
findProgs p0 = do
    a <- validPrefix p0

    let withoutA = splitOn' a p0
    b <- case withoutA of
        []        -> empty              -- 'A' consumed everything, whoops
        bs : _    -> validPrefix bs

    let withoutB = splitOn' b =<< withoutA
    c <- case withoutB of
        []        -> empty              -- 'A' and 'B' consumed everything, whoops
        cs : _    -> validPrefix cs

    let withoutC = splitOn' c =<< withoutB
    guard $ null withoutC

    pure (a, b, c)
  where
    -- | Get all valid prefixes
    validPrefix = take 4 . filter (not . null) . inits
    -- | a version of splitOn that only returns non-empty lists
    splitOn' x = filter (not . null) . splitOn x
```

Note that here I am using a simple predicate to filter out subprograms that are
"too long" (the `take 4` in `validPrefix`).  For a more robust solution, we can
do `validPrefix = filter validLength . inits`, testing on the length of the
strings that encode the programs.

And that is mostly it!  We can reconstruct our original program by using
iterated applications of `stripPrefix`, taking whatever prefix is *valid* at
every point:

```haskell
-- | Given an association list of subroutines and their "label", iteratively
-- chomp through a string replacing each occurence of the subroutine with the
-- label.
chomp :: Eq a => [([a], b)] -> [a] -> [b]
chomp progs = unfoldr go
  where
    go xs = asum
      [ (r,) <$> stripPrefix prog xs
      | (prog, r) <- progs
      ]
```

The nice thing about writing these functions "in general" (instead of just )

And our final solution is, given a set of scaffolding points and an initial bot
state:

```haskell
data Prog = A | B | C

data Output = O
    { oProg :: [Prog]
    , oA    :: [Either Int Int]
    , oB    :: [Either Int Int]
    , oC    :: [Either Int Int]
    }

part2 :: Set Point -> BotState -> Maybe Output
part2 scaff b0 = listToMaybe (findProgs path) <&> \(a,b,c) ->     -- <&> is flip fmap
    O { oProg = chomp [(a, A), (b, B), (c, C)] path
      , oA    = a
      , oB    = b
      , oC    = c
      }
  where
    path = findPath scaff b0
```


### Day 17 Benchmarks

```
>> Day 17a
benchmarking...
time                 47.27 μs   (46.96 μs .. 47.75 μs)
                     0.997 R²   (0.993 R² .. 1.000 R²)
mean                 47.81 μs   (47.13 μs .. 49.59 μs)
std dev              3.244 μs   (746.8 ns .. 5.699 μs)
variance introduced by outliers: 70% (severely inflated)

* parsing and formatting times excluded

>> Day 17b
benchmarking...
time                 111.6 μs   (110.6 μs .. 113.6 μs)
                     0.999 R²   (0.997 R² .. 1.000 R²)
mean                 111.9 μs   (111.1 μs .. 114.4 μs)
std dev              4.845 μs   (1.746 μs .. 8.760 μs)
variance introduced by outliers: 45% (moderately inflated)

* parsing and formatting times excluded
```

